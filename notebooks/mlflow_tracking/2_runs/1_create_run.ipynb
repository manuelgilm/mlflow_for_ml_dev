{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runs \n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"../../images/mlflow_run.jpeg\" alt=\"MLFlow Run\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "A MLflow run is a unit of work in MLflow that represents the execution of a machine learning experiment or a piece of code. It tracks the parameters, metrics, artifacts, and metadata associated with the run. MLflow runs allow you to log and track experiments, compare different runs, and reproduce results. Each run is associated with an experiment and can have multiple tags, parameters, metrics, and artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a MLflow Run\n",
    "\n",
    "### Using start_run\n",
    "\n",
    "```python\n",
    "mlflow.start_run()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow \n",
    "from mlflow_for_ml_dev.experiments.exp_utils import get_or_create_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"creating_runs\"\n",
    "tags = {\"project_name\":\"UNDEFINED\", \"topic\":\"run_management\"}\n",
    "experiment = get_or_create_experiment(experiment_name=experiment_name, tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tags = {\"tag1\": \"value1\", \"tag2\": \"value2\"}\n",
    "run = mlflow.start_run(\n",
    "    run_name = \"Run 1\",\n",
    "    experiment_id = experiment.experiment_id,\n",
    "    description=\"This is a run description\",\n",
    "    tags= run_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.to_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_run = mlflow.active_run()\n",
    "print(type(active_run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the context Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> About `mlflow.start_run()`\n",
    "> \n",
    "> The return value of `mlflow.start_run()` can be used as a context manager within a `with` block. Otherwise, you must call `end_run()` to terminate the current run.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "with mlflow.start_run() as run:\n",
    "    print(\"Log metrics and params\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run() # end the active run to start a new one\n",
    "with mlflow.start_run(run_name=\"Run 2\", experiment_id=experiment.experiment_id) as run:\n",
    "    active_run = mlflow.active_run()\n",
    "    print(type(active_run))  \n",
    "    print(\"Active Run: \", run.info.run_id)\n",
    "    print(\"\\n \\n\")\n",
    "\n",
    "\n",
    "\n",
    "active_run = mlflow.active_run()\n",
    "print(type(active_run))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_run = client.create_run(experiment_id=experiment.experiment_id, run_name=\"test_run\", tags={\"tag1\": \"value1\", \"tag2\": \"value2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.active_run()\n",
    "type(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Run Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Run 3\", experiment_id=experiment.experiment_id) as run:\n",
    "    mlflow.set_tag(\"tag3\", \"value3\")\n",
    "    \n",
    "    # Set tags\n",
    "    mlflow.set_tags({\"tag4\": \"value4\", \"tag5\": \"value5\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update run description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Run 4\", experiment_id=experiment.experiment_id) as run:\n",
    "    #Update description\n",
    "    mlflow.set_tag(\"mlflow.note.content\", \"This is a new description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve run information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.get_run(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.data.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
