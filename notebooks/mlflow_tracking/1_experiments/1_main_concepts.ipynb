{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Tracking\n",
    "\n",
    "The MLflow Tracking is an API and UI for logging parameters, code versions, metrics, and output files when running your machine learning code and for later visualizing the results.\n",
    "\n",
    "## Concepts\n",
    "\n",
    "![Taken from MLflow Docs](https://mlflow.org/docs/latest/_images/tracking-basics.png)\n",
    "\n",
    "**Runs**\n",
    "\n",
    "MLflow Tracking is organized around the concept of runs, which are executions of some piece of data science code, for example, a single python train.py execution.\n",
    "\n",
    "\n",
    "**Experiments** \n",
    "\n",
    "An experiment groups together runs for a specific task. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Tracking URI\n",
    "\n",
    "Set the tracking server URI. \n",
    "\n",
    "`mlflow.set_tracking_uri(uri: Union[str, pathlib.Path]) → None[source]`\n",
    "\n",
    "Parameters:\n",
    "* uri:\n",
    "\n",
    "    * An empty string, or a local file path, prefixed with file:/. Data is stored locally at the provided file (or ./mlruns if empty).\n",
    "\n",
    "    * An HTTP URI like https://my-tracking-server:5000.\n",
    "\n",
    "    * A Databricks workspace, provided as the string “databricks”\n",
    "\n",
    "    * A pathlib.Path instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow_for_ml_dev.experiments.exp_utils import get_or_create_experiment\n",
    "from mlflow_for_ml_dev.experiments.exp_utils import print_experiment_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = \"Default\"\n",
    "experiment = get_or_create_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Experiment Information \n",
      "\n",
      "Name: Default\n",
      "Experiment_id: 0\n",
      "Artifact Location: file:///C:/Users/manue/projects/mlflow_for_ml_dev/mlruns/0\n",
      "Tags: {}\n",
      "Lifecycle_stage: active\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_experiment_info(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1712406896557"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.creation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/manue/projects/mlflow_for_ml_dev/mlruns/0', creation_time=1712406896557, experiment_id='0', last_update_time=1712406896557, lifecycle_stage='active', name='Default', tags={}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
